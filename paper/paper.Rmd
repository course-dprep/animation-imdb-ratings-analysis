---
title: '**About Time: Investigating IMDb Movie Ratings with Release Year and the Effect of Animation**'
date: "`r Sys.Date()`"
author:
  - "Britt van Haaster, Isah Huijbregts, Lars van der Kroft"
  - "Amanda van Lankveld, Amy Quist, Stefan Valentijn"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    latex_engine: xelatex
---

\newpage

## Chapter 1: Introduction

### Motivation

Movies -a form of entertainment that has been around for centuries. Yet, the distribution and consumer perceptions of movies have shifted since the introduction of streaming services (Hennig-Hurau et al., 2021; Kumar, 2023). In 2010, the international expansion of Netflix across the globe marked a key point in the growth of on-demand content (Oberoj, 2024). The saturation and availability of the entertainment market have resulted in more critical consumers, which seemingly affects how audiences evaluate films (Hadida et al., 2020). Although research has been performed on movie ratings over time (e.g. Moon et al., 2010; Ramos et al., 2015), the effect of streaming remains rather unexplored.

Over the years, black-and-white silent movies have advanced to colourful and effects-heavy motion pictures due to technological developments. This is especially prominent in animation, where disruptions in Computer Generated Images (CGI) and production techniques have significantly enhanced visual quality and storytelling opportunities (Sun, 2023). Consequently, this makes it plausible to assume audience evaluations of animated films could differ from live-action films. Yet, current research has not addressed this focus on animation. All in all, the present study provides academic relevance by investigating the temporal dynamics on the quality perception of movies, while also accounting for the effect of animation. These insights are also socially relevant for filmmakers and distributors to better understand audiences. The focus of the research can be encapsulated with the following research question:

### Research Question

*To what extent does the release year of a movie influence its average IMDb rating, and does this relationship differ between animated and non-animated films?*

\newpage

## Chapter 2: Literature Review

In 2010, Netflix released globally, with more streaming services having entered the market ever since with players such as Disney+, Amazon Prime Video and HBO Max. Competitiveness rose, resulting in a greater variety of TV shows and movies offered (Thompson, 2024). Simultaneously, the more experienced a viewer is in watching movies, the more critical they tend to become (Moon et al., 2009). As such, it could be expected that newer movies are rated worse than older movies because the frame of reference has increased. Additionally, with the rise of digital platforms and social media, review-bombing has become an omnipresent phenomenon upon the release of new films. Moreover, there has been an increasingly vocal group that criticizes the franchise- and sequel-based strategies that movie corporations have adopted. Furthermore, it could be argued that movie consumers often experience nostalgia for films watched in their childhood, resulting in higher ratings for older movies. Authors such as Bollen et al. (2012) refer to this as a form of “positivity effect”. Overall, the present study examines whether the introduction of streaming services has an effect on the average rating of films by testing;

***H1:*** _Movies released since 2010 receive lower average ratings than movies released before 2010._

Movies can comprise of many different genres. In terms of the effect of time, the particular interest of the present study, different results could be expected from animation versus live-action movies. For instance, animated films are more easily regarded as timeless, while live-action movies risk the fact these could become outdated due to changes in fashion, technology or cultural norms, while animation movies remain fairly consistent over time (Larson, 2025). Furthermore, live-action more heavily depend on the actors, who visibly age, while animated characters remain fairly consistent over time. For example, Woody from Toy Story remains unchanged in sequels decades after his debut in 1995. In line with this, this results in more frequent intergenerational re-watches for animation movies (Lizardi, 2020), as these are also often targeted at children and families. This strengthens the sense of nostalgia and therefore the aforementioned positivity effect. The present study inspects whether animation movies are rated differently from non-animation movies by testing:

***H2:*** _The negative effect of release year (before vs since 2010) on ratings is moderated by animation status, in that the decline is less pronounced for animated movies than for non-animated movies._

\newpage

## Chapter 3: Methodology

### Data

In order to test H1 and H2 and therefore answer the main research question, secondary data is consulted from [IMDb.com](https://developer.imdb.com/non-commercial-datasets/). The database holds several datasets, of which two provide relevance in the context of the present study:

1. [title.basics.tsv.gz](https://datasets.imdbws.com/title.basics.tsv.gz), which contains information about the title, runtime, genre and release year of motion pictures.

2. [title.rating.tsv.gz](https://datasets.imdbws.com/title.ratings.tsv.gz), which provides data on ratings for all titles. These IMDb ratings are derived from IMDb users and can comprise of movie consumers or professionals.

The dataset merged from the secondary data contains the following variables:

| Variable          | Type      | Definition                                                             |
|-------------------|-----------|-------------------------------------------------------------------------|
| tconst            | character | Unique IMDb identifier for each title                                   |
| primaryTitle      | character | The title most commonly used by the general public                      |
| startYear         | integer   | Year the title was released                                             |
| runtimeMinutes    | integer   | Runtime expressed in minutes                                            |
| genres            | character | Genres separated by commas                                              |
| averageRating     | numeric   | Weighted average IMDb user rating (0.0–10.0)                            |
| numVotes          | integer   | Number of votes received by the title                                   |

In further testing the hypotheses, two dummy variables were feature engineered;

| Variable          | Type      | Definition                                                             |
|-------------------|-----------|-------------------------------------------------------------------------|
| before_2010_dummy | dummy     | Whether a movie is released before or after 2010                        |
| animation_dummy   | dummy     | Whether a movie is animated or not                                      |

### Type of Analyses

First of all, **descriptive statistics** were performed on the data. For a more insightful interpretation, descriptives were generated on four subsets that were created based on the two dummy variables;

- Animation movies
- Non-Animation movies
- Movies released before 2010
- Movies released since 2010

In further assessment of whether there was a significant difference in rating between animation and non-animation movies, an **independent t-test** was performed. For this, the procedure of Hair et al. (2019) was adopted. An additional test was performed to assess difference in rating of movies released before 2010 and since 2010.

To test H1 and H2, a **linear regression** was conducted in R Studio. This method was chosen because it allows for examining the relationship between a continuous dependent variable (average IMDb rating) and multiple continuous or categorical independent variables, including interactions. For the independent variables, these were entered step-wise in three models, and then assessed on fitness based on the F-statistic and the Adjusted R². The following three hierarchical regression models were estimated;

1. *Model 1*: including the basic predictors. Whether a movie was an animation was dummy-coded into the variable `animation_dummy` (0 = non-animated, 1 = animated), while the release year was stored into `before_2010_dummy` (0 = since 2010, 1 = before 2010) and included. The interaction between variables was not yet tested in model 1.

2. *Model 2*: including the basic predictors and control variables. Other potential factors that were not specifically hypothesised but could influence ratings were added as control variables in model 2. This included `startYear`, `runtimeMinutes` and `numVotes`. In verifying whether the assumption of linearity was met, it was revealed to be violated for `runtimeMinutes` and `numVotes`, whereby these have been log transformed and entered into the model as `log_runtimeMinutes` and `log_numVotes`. 

3. *Model 3*: including the basic predictors and control variables and interactions. The expected moderation effects between `before_2010_dummy` and `animation_dummy`, and `animation_dummy` and `startYear` was included in order to test H1 and H2.

Besides the unstandardised effects, the standardised effects were also calculated since these allow to compare coefficients on their magnitude. Following the procedure of Field (2018) and Hair et al. (2019), each regression model was checked on the following assumptions;

- *Normality*: using the Shapiro-Wilk test, the Kolmogorov-Smirnov test and a histogram of residuals
- *Homoscedasticity* and *Linearity*: using a ZPRED vs ZRESID plot
- *Multicollinearity*: using the Variance Inflation Factor
- *Independence*: using the Durbin-Watson test

\newpage

## Chapter 4: Findings

### Descriptive Statistics

Elaborated descriptives and visualisations can be consulted from the separate data exploration file. Solely the information key to answering the hypotheses are presented in this chapter.

Below, descriptive statistics of the key numeric variables are presented. Most of the dataset contains non-animation movies. In fact, there are roughly 35 times more non-animation movies than animation ones. The **average runtime** is fairly consistent for the different subsets, ranging between 90 and 100 minutes. Animation movies tend to be slightly shorter. When it comes to **average ratings**, animated titles tend to score slightly higher on average, with a mean of 6.5 compared to 6.2 for other genres. Additionally, the standard deviation is the lowest for the average rating of animation movies, which suggests the most consensus amongst the critics. There seems to be less variance in the average rating for the startyear subsets, with also similar standard deviations. For the **number of votes**, it can be seen that animation movies receive a higher number than non-animation movies -nearly 1.5 times more votes. Older movies released before 2010 also have more votes than those released since 2010.

| Subset        | Observations | Mean runtime minutes | Mean averageratings | SD averageratings | Mean number of votes |
| ------------- | ------------ | -------------------- | ------------------- | ----------------- | -------------------- |
| Animation     | 1,846        | 90.5                 | 6.51                | 1.08              | 43,393               |
| Non-Animation | 64,051       | 96.8                 | 6.22                | 1.17              | 30,608               |
| Before 2010   | 20,537       | 97.0                 | 6.29                | 1.14              | 35,085               |
| Since 2010    | 45,360       | 96.4                 | 6.20                | 1.18              | 29,101               |

### Visualisation of Data

Since the average rating is the particular interest of this study, it is intriguing to further visualise this dependent variable. The descriptives revealed a higher rating for animation movies when compared to non-animation movies. The **line plot** below further visualises this trend for the release year period of 1995 up to and including 2025. The graph confirms that the average rating are close but typically rated somewhat higher for animation movies.

```{r, echo=FALSE, out.width="60%", fig.align="center"}
# Line plot, average rating per year per type
knitr::include_graphics("../gen/output/line_avg_rating_by_type.png")
```

As the scores from the graph above are on a scale of 0-10, another **smooth plot** can be created to assess the trends in rating on a close scale. Over time, the average rating for animation movies seems declining, while non-animation movies have seen a decline and then a slight increase over the years. Nevertheless, animation movies are still rated higher.

```{r, echo=FALSE, out.width="60%", fig.align="center"}
# Smooth plot, average rating per year per type
knitr::include_graphics("../gen/output/smooth_avg_rating_by_type.png")
```

### T-Tests

The average rating for animation movies with 6.51 (SD = 1.08) is higher then for non-animation movies with 6.22 (SD = 1.17). In further solidifying this, the independent t-test (see the full output in Appendix I) found that this difference, 0.29, BCa 95% CI [0.241, 0.341}, is significant t(1973) = 11.417, p = \<0.001. Thus, on average, animation movies receive higher grades than non-animation movies. This is in line with the visualisation in the previous section, which shows animation movies on average score consistently higher than non-animation movies.

Movies released before 2010 receive significantly higher ratings than those released since 2010, as resulting from the second independent t-test (see Appendix I for the full output). On average, movies released since 2010 score a 6.2 (SD = 1.18), while those released before 2010 score a 6.3. Although minimal, this difference, 0.09, 95% CI [0.069, 0.106], is statistically significant, t(41202) = 9.03, p = \<0.001.

### Regression Analysis

As for the *findings*, the full regression output can be consulted in Appendix II. Summaries are provided in Table 4 (= MODEL 1), Table 5 (= MODEL 2) and Table 6 (= MODEL 3) below.

```{r results='asis', message = FALSE, warning = FALSE, echo = FALSE}

#Load package for visualisation
library(stargazer)

#Load final model
model1 <- readRDS("../gen/output/MODEL1_unstandardised.rds")

#Capture stargazer
stargazer_tex1 <- capture.output(
  stargazer(model1,
            type = "latex",
            title = "Regression Results OF MODEL 1",
            label = "tab:regression",
            dep.var.labels = "Average Rating",
            digits = 3,
            out.header = FALSE,
            no.space = TRUE,
            notes.append = FALSE)
)

#Remove automated stargazer message
stargazer_tex_clean1 <- stargazer_tex1[!grepl("^%", stargazer_tex1)]

#Summarise clean table
cat(paste(stargazer_tex_clean1, collapse = "\n"))

```

```{r results='asis', message = FALSE, warning = FALSE, echo = FALSE}

#Load package for visualisation
library(stargazer)

#Load final model
model2 <- readRDS("../gen/output/MODEL2_unstandardised.rds")

#Capture stargazer
stargazer_tex2 <- capture.output(
  stargazer(model2,
            type = "latex",
            title = "Regression Results OF MODEL 2",
            label = "tab:regression",
            dep.var.labels = "Average Rating",
            digits = 3,
            out.header = FALSE,
            no.space = TRUE,
            notes.append = FALSE)
)

#Remove automated stargazer message
stargazer_tex_clean2 <- stargazer_tex2[!grepl("^%", stargazer_tex2)]

#Summarise clean table
cat(paste(stargazer_tex_clean2, collapse = "\n"))

```

Model 2 and model 2 both show a significant F-statistic (p < 0.001). As for the Adjusted R², model 1 explains solely 0.3% of variance, while model 2 explains 5.9% -which is quite low. In both Model 1 and Model 2, the **2010 dummy** has a significant negative effect on average movie ratings (p < 0.001). This can be interpreted in that movies released since 2010 receive lower ratings than those released before 2010. In the most basic model, this is 0.088 points lower, while in model 2 this difference decreases slightly to 0.070. In both models, the **animation dummy** is also significant and a negative effect (p < 0.001), whereby it can be interpreted that non-animation movies score significantly worse than non-animation movies in terms of the average rating. The value is -0.293 in model 1 and declines to -0.249 in model 2. In model 2, the runtime and number of votes are significant pedictors.

\newpage

```{r results='asis', message = FALSE, warning = FALSE, echo = FALSE}

#Load package for visualisation
library(stargazer)

#Load final model
model3 <- readRDS("../gen/output/MODEL3_unstandardised.rds")

#Capture stargazer
stargazer_tex3 <- capture.output(
  stargazer(model3,
            type = "latex",
            title = "Regression Results OF MODEL 3",
            label = "tab:regression",
            dep.var.labels = "Average Rating",
            digits = 3,
            out.header = FALSE,
            no.space = TRUE,
            notes.append = FALSE)
)

#Remove automated stargazer message
stargazer_tex_clean3 <- stargazer_tex3[!grepl("^%", stargazer_tex3)]

#Summarise clean table
cat(paste(stargazer_tex_clean3, collapse = "\n"))

```

Model 3 adds the interaction terms to examine whether the relationship between release year and ratings differs between animated and non-animated films. The F-statistic is significnat (p < 0.001), and the Adjusted R² is 5.9% -similar as model 2. Neither the interaction between the 2010 dummy × animation dummy nor the interaction between start year × animation dummy is statistically significant (p > 0.05). This suggests no effect that the relationship between release year and ratings depends on animation status. The control variables (runtime and number of votes) remain significant and positive across models.

\

Regarding the *assumptions* of the models, Appendix III shows the full output of the assumptions checking of the regression models. The table below summarises the assumptions of model 3, since that model encapsulated the focus of the present study.

|        | Normality                                                                 | Linearity                              | Homoscedasticity                             | Multicollinearity                          | Independence                       |
|------------------|---------------------------------------------------------------------------|----------------------------------------|----------------------------------------------|-------------------------------------------|------------------------------------|
| **Tested**       | Shapiro-Wilk + Kolmogorov-Smirnov + Histogram show non-normality| ZPRED vs ZRESID shows linearity        | ZPRED vs ZRESID shows heteroscedasticity     | Variance Inflation Factor shows no problem          | Durbin-Watson shows no problem      |
| **Verdict**      | **VIOLATED**                                                              | **MET**                                | **VIOLATED**                                 | **MET**                                   | **MET**                             |

As the table shows, the assumptions of linearity, multicollinearity and independence of errors are met, while the assumption of normality and homoscedasticity are violated. This is presumably a result of the disproportion between the number of non-animation and animation movies, which may distort residual patterns and inflate variance across groups.

\newpage

## Chapter 5: Conclusions and Discussion

### Conclusion

This paper is interested the extent to which the release year of a movie influences its average IMDb rating, and whether this is different between animated and non-animated films. An answer can be given to this question based on the two hypotheses;

***H1:*** _Movies released since 2010 receive lower average ratings than movies released before 2010._

*Verdict*: The t-test confirms that movies released before 2010 receive a higher rating than those since 2010. In addition, the results of model 1 and 2 indicate that movie ratings have declined slightly in the post-2010 era, supporting the notion that audiences have become more critical in the age of streaming. However, in model 3 including the interaction, this effect becomes statistically insignificant. This suggests that the simple main effect of release period does not hold when accounting for moderated effects. In addition, temporal shift explains only a small portion of the variation in ratings, suggesting that other factors such as popularity and runtime play a more substantial role in how movies are evaluated. **Therefore, H1 is partially supported**.

***H2:*** _The negative effect of release year (before vs since 2010) on ratings is moderated by animation status, in that the decline is less pronounced for animated movies than for non-animated movies._

*Verdict*: The t-test confirms animation movies receive a higher rating than non-animation movies. Nevertheless, regression model 3 shows none of the interactions to be significant. **Therefore, H2 is rejected**.

### Discussion

The findings show a slight but significant decline in average ratings for films released after 2010, providing partial support for H1. This outcome aligns with Moon et al. (2009), who argue that audiences have become more critical as their exposure to films increases. Likewise, Hadida et al. (2020) and Hennig-Thurau et al. (2021) describe how the streaming era has intensified competition and expanded consumer choice, which may lead viewers to evaluate movies more harshly. Thus, the current results reinforce the notion that the expansion of digital content and on-demand viewing has reshaped expectations of film quality. Nevertheless, it should be noted that the decline in rating is relatively small. from 6.29 to 6.20.

However, while a temporal effect on ratings was confirmed, the moderation effect of animation (H2) was not supported. Contrary to Larson (2025), who proposed that animated films are perceived as more timeless due to their visual consistency and limited dependence on aging actors, the present analysis found no significant difference in how ratings changed over time for animation compared to live action. One possible explanation is that animated films have also evolved considerably in style and storytelling sophistication. As animation increasingly targets adult audiences, nostalgia may be offset by higher critical standards and greater scrutiny of production quality. Furthermore, because animated movies make up a smaller portion of total releases, any distinct pattern may be diluted by the predominance of live-action titles in the data set.

Although statistically significant, the models explain only a small proportion of variance in IMDb ratings (adjusted R² of model 3 = 0.059). This indicates that the timing of release alone cannot account for the complexity of audience evaluations. Other influences, such as genre preferences, marketing exposure, critical reviews, or star power, likely play a much larger role. Nevertheless, the study provides empirical support for the idea that streaming-era audiences have become incrementally more discerning and that this shift applies broadly across both animated and non-animated movies.

\newpage

### Limitations

Several limitations should be considered when interpreting these findings. Firstly, the analysis relied solely on IMDb data, which represents a self-selected community of users rather than a random sample of movie consumers in general. Ratings on the platform may therefore reflect demographic or cultural biases, such as the overrepresentation of younger or more cinephile-type of audiences.

Furthermore, the dataset captured IMDb scores at a single point in time. However, because ratings can evolve after release, possibly increasing with nostalgia or decreasing due to review-bombing, the cross-sectional nature of the data prevents analysis of longitudinal rating changes.

Another limitation is that the temporal variable was simplified into a binary indicator (before vs. since 2010). While this aligns with the introduction of major streaming services, it limits the ability to detect gradual or nonlinear trends across individual years.

Moreover, the genre variable consisted of a large variety, including many overlapping genres. This may have biased the results. Many animation movies also belonged to other genres such as adventure or comedy, but the effect of this on the average rating has not been examined in this study.

From a statistical point of view, several regression assumptions, specifically normality and homoscedasticity, were violated, as shown in Appendix III. These violations are likely a result of the large sample size and the nature of IMDb ratings, which are bounded between 0 and 10 and tend to cluster towards higher scores. As Field (2018) notes, even small deviations from normality can appear statistically significant when working with large data sets. Although such violations are common in social-science data and may not critically distort the estimates, they can reduce the precision of statistical inference and should be interpreted with caution. However, it is also important to note that these assumptions are not considered the most important of all the necessary assumptions and thus should not pose too much of a concern.

### Future Research

With new data being processed on a daily basis, the analysis of IMDb data sets remains an ongoing process. By repeating this type of research over time it could reveal potential trends in IMDb ratings for animation movies compared to non-animated movies. This is especially intriguing since the visual exploration of the data revealed animation movies are rated higher, yet 2025 seems to be a tipping point. A longitudinal design for a future study would thus be of a particular interest.

The relatively low adjusted R² suggests a low explanatory power of the variables included in this study. Rather, factors such as the production budget, marketing effort, or critical acclaim -which were not provided in the IMDb-datasets used in the present study- could be included in future studies to provide further light on this phenomenon.

Future research could focus more on the role of movie popularity and its influence on IMDB rating. Many animated films are reboots of older, nostalgic classics, which may affect audiences perception and engagement. These type of movies might attract more reviews due to their established fan base and may receive more critical evaluations because viewers have a direct point of c comparison with the original.

In addition, it would be valuable to examine whether there is a significant different in ratings between animated reboots and newly created animated concepts. These researches can also be done on TV shows, bring a different angle with some shows from gen-z youth still continuing to be produced in current day of time.

\newpage

## Reference List

Bollen, D., Graus, M. P., & Willemsen, M. C. (2012). Remembering the stars?: effect of time on preference retrieval from memory. Proceedings of the sixth ACM conference on Recommender systems.<https://doi.org/10.1145/2365952.2365998>

Hadida, A. L., Lampel, J., Walls, W. D., & Joshi, A. (2020). Hollywood Studio Filmmaking in the Age of Netflix: a Tale of Two Institutional Logics. Journal of Cultural Economics, 45(2), 213–238. <https://doi.org/10.1007/s10824-020-09379-z>

Hennig-Thurau, T., Ravid, S. A., & Sorenson, O. (2021). The Economics of Filmed Entertainment in the Digital Era. Journal of Cultural Economics, 45(2), 157–170. <https://doi.org/10.1007/s10824-021-09407-6>

Kumar, L. (2023, April). A Study On The Impact Of The OTT Platform On The Cinema With The Special Reference On The Cinema Audience. ResearchGate; unknown. <https://www.researchgate.net/publication/376650380_A_Study_On_The_Impact_Of_The_OTT_Platform_On_The_Cinema_With_The_Special_Reference_On_The_Cinema_Audience>

Larson, V. J. (2025). Philosophy in filmmaking: Animation vs. live action (Honors Program Theses No. 976) [Undergraduate thesis, University of Northern Iowa]. University of Northern Iowa Repository. <https://scholarworks.uni.edu/cgi/viewcontent.cgi?article=2004&context=hpt>

Lizardi, R. (2020). The future of nostalgia is inevitable: Reflections on mediated nostalgia. In M. H. Jacobsen (Ed.), Nostalgia Now: Cross-disciplinary perspectives on the past in the present (1st ed., pp. 147-161). Routledge. <https://doi.org/10.4324/9780429287602-8>

Moon, S., Bergey, P. K., & Iacobucci, D. (2009). Dynamic Effects among Movie Ratings, Movie Revenues, and Viewer Satisfaction. Journal Of Marketing, 74(1), 108–121. <https://doi.org/10.1509/jmkg.74.1.108>

Oberoi, S. (2024, December 3). The Evolution of Netflix: from DVD Rentals to Global Streaming Leader. Seat11a.com. <https://seat11a.com/blog-the-evolution-of-netflix-from-dvd-rentals-to-global-streaming-leader/>

Ramos, M., Calvão, A. M., & Anteneodo, C. (2015). Statistical patterns in movie rating behavior. PLOS ONE, 10(8), e0136083. <https://doi.org/10.1371/journal.pone.0136083>

Sun, Z. (2023). What does cgi digital technology bring to the sustainable development of animated films?. Sustainability, 15(14), 10895. <https://doi.org/10.3390/su151410895>

Thompson, B. (2024, May 25). The Rise and Fall of Streaming TV? –Michigan Journal of Economics. Michigan Journal of Economics. <https://sites.lsa.umich.edu/mje/2024/05/25/the-rise-and-fall-of-streaming-tv/>

\newpage

## Appendix I - Results T-Test

**T-Test for difference in rating between animation and non-animation movies**

```{r first independent t-test, echo=FALSE}
print(readLines("../gen/output/ttest_rating.txt", warn = FALSE, encoding = "UTF-8"))
```

**T-Test for difference in rating between movies released before 2010 and released since 2010**

```{r second independent t-test, echo=FALSE}
print(readLines("../gen/output/ttest_release.txt", warn = FALSE, encoding = "UTF-8"))
```

\newpage

## Appendix II - Results Multiple Regression

**Model 1**

```{r model 1, echo=FALSE}
model1 <- print(readLines("../gen/output/lr_model_basic.txt", warn = FALSE, encoding = "UTF-8"))
```

\newpage

**Model 2**

```{r model 2, echo=FALSE}
model2 <- print(readLines("../gen/output/lr_model_with_control_variables.txt", warn = FALSE, encoding = "UTF-8"))
```

\newpage

**Model**

```{r model 3, echo=FALSE}
model3 <- print(readLines("../gen/output/lr_model_with_interaction.txt", warn = FALSE, encoding = "UTF-8"))
```

\newpage

## Appendix III -Assumptions Results Multiple Regression

**Assumptions model 1**

```{r assumptions model 1, echo=FALSE}
assumptionsmodel1 <- print(readLines("../gen/output/assumption_checks_model1.txt", warn = FALSE, encoding = "UTF-8"))
```

```{r fig.align='center', echo=FALSE, out.width='50%'}
knitr::include_graphics("../gen/output/assumptions_histogram_MODEL1_unstandardised.png")
```

```{r fig.align='center', echo=FALSE, out.width='50%'}
knitr::include_graphics("../gen/output/assumptions_plot_ZPREDvsZRESID_MODEL1_unstandardised.png")
```

\newpage

**Assumptions model 2**

```{r assumptions model 2, echo=FALSE}
assumptionsmodel2 <- print(readLines("../gen/output/assumption_checks_model2.txt", warn = FALSE, encoding = "UTF-8"))
```

```{r fig.align='center', echo=FALSE, out.width='50%'}
knitr::include_graphics("../gen/output/assumptions_histogram_MODEL2_unstandardised.png")
```

```{r fig.align='center', echo=FALSE, out.width='50%'}
knitr::include_graphics("../gen/output/assumptions_plot_ZPREDvsZRESID_MODEL2_unstandardised.png")
```

\newpage

**Assumptions model 3**

```{r assumptions model 3, echo=FALSE}
assumptionsmodel3 <- print(readLines("../gen/output/assumption_checks_model3.txt", warn = FALSE, encoding = "UTF-8"))
```

```{r fig.align='center', echo=FALSE, out.width='50%'}
knitr::include_graphics("../gen/output/assumptions_histogram_MODEL3_unstandardised.png")
```

```{r fig.align='center', echo=FALSE, out.width='50%'}
knitr::include_graphics("../gen/output/assumptions_plot_ZPREDvsZRESID_MODEL3_unstandardised.png")
```
