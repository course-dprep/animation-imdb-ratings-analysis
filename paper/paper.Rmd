---
title: '**About Time: Investigating IMDb Movie Ratings with Release Year and the Effect of Animation**'
date: "`r Sys.Date()`"
author:
  - "Britt van Haaster, Isah Huijbregts, Lars van der Kroft"
  - "Amanda van Lankveld, Amy Quist, Stefan Valentijn"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    latex_engine: xelatex
---

\newpage

## Chapter 1: Introduction

### Motivation

Movies -a form of entertainment that has been around for centuries. Yet, the distribution and consumer perceptions of movies have shifted since the introduction of streaming services (Hennig-Hurau et al., 2021; Kumar, 2023). In 2010, the international expansion of Netflix across the globe marked a key point in the growth of on-demand content (Oberoj, 2024). The saturation and availability of the entertainment market have resulted in more critical consumers, which seemingly affects how audiences evaluate films (Hadida et al., 2020). Although research has been performed on movie ratings over time (e.g. Moon et al., 2010; Ramos et al., 2015), the effect of streaming remains rather unexplored.

Over the years, black-and-white silent movies have advanced to colourful and effects-heavy motion pictures due to technological developments. This is especially prominent in animation, where disruptions in Computer Generated Images (CGI) and production techniques have significantly enhanced visual quality and storytelling opportunities (Sun, 2023). Consequently, this makes it plausible to assume audience evaluations of animated films could differ from live-action films. Yet, current research has not addressed this focus on animation. All in all, the present study provides academic relevance by investigating the temporal dynamics on the quality perception of movies, while also accounting for the effect of animation. These insights are also socially relevant for filmmakers and distributors to better understand audiences. The focus of the research can be encapsulated with the following research question:

### Research Question

*To what extent does the release year of a movie influence its average IMDb rating, and does this relationship differ between animated and non-animated films?*

\newpage

## Chapter 2: Literature Review

In 2010, Netflix released globally, with more streaming services having entered the market ever since with players such as Disney+, Amazon Prime Video and HBO Max. Competitiveness rose, resulting in a greater variety of TV shows and movies offered (Thompson, 2024). Simultaneously, the more experienced a viewer is in watching movies, the more critical they tend to become (Moon et al., 2009). As such, it could be expected that newer movies are rated worse than older movies because the frame of reference has increased. Additionally, with the rise of digital platforms and social media, review-bombing has become an omnipresent phenomenon upon the release of new films. Moreover, there has been an increasingly vocal group that criticizes the franchise- and sequel-based strategies that movie corporations have adopted. Furthermore, it could be argued that movie consumers often experience nostalgia for films watched in their childhood, resulting in higher ratings for older movies. Authors such as Bollen et al. (2012) refer to this as a form of “positivity effect”. Overall, the present study examines whether the introduction of streaming services has an effect on the average rating of films by testing;

***H1:*** _Movies released since 2010 receive lower average ratings than movies released before 2010._

Movies can comprise of many different genres. In terms of the effect of time, the particular interest of the present study, different results could be expected from animation versus live-action movies. For instance, animated films are more easily regarded as timeless, while live-action movies risk the fact these could become outdated due to changes in fashion, technology or cultural norms, while animation movies remain fairly consistent over time (Larson, 2025). Furthermore, live-action more heavily depend on the actors, who visibly age, while animated characters remain fairly consistent over time. For example, Woody from Toy Story remains unchanged in sequels decades after his debut in 1995. In line with this, this results in more frequent intergenerational re-watches for animation movies (Lizardi, 2020), as these are also often targeted at children and families. This strengthens the sense of nostalgia and therefore the aforementioned positivity effect. The present study inspects whether animation movies are rated differently from non-animation movies by testing:

***H2:*** _The negative effect of release year (before vs since 2010) on ratings is moderated by animation status, in that the decline is less pronounced for animated movies than for non-animated movies._

\newpage

## Chapter 3: Methodology

### Data

In order to test H1 and H2 and therefore answer the main research question, secondary data is consulted from [IMDb.com](https://developer.imdb.com/non-commercial-datasets/). The database holds several datasets, of which two provide relevance in the context of the present study:

1. [title.basics.tsv.gz](https://datasets.imdbws.com/title.basics.tsv.gz), which contains information about the title, runtime, genre and release year of motion pictures.

2. [title.rating.tsv.gz](https://datasets.imdbws.com/title.ratings.tsv.gz), which provides data on ratings for all titles. These IMDb ratings are derived from IMDb users and can comprise of movie consumers or professionals.

The dataset merged from the secondary data contains the following variables:

| Variable          | Type      | Definition                                                             |
|-------------------|-----------|-------------------------------------------------------------------------|
| tconst            | character | Unique IMDb identifier for each title                                   |
| primaryTitle      | character | The title most commonly used by the general public                      |
| startYear         | integer   | Year the title was released                                             |
| runtimeMinutes    | integer   | Runtime expressed in minutes                                            |
| genres            | character | Genres separated by commas                                              |
| averageRating     | numeric   | Weighted average IMDb user rating (0.0–10.0)                            |
| numVotes          | integer   | Number of votes received by the title                                   |

In further testing the hypotheses, two dummy variables were feature engineered;

| Variable          | Type      | Definition                                                             |
|-------------------|-----------|-------------------------------------------------------------------------|
| before_2010_dummy | dummy     | Whether a movie is released before or after 2010                        |
| animation_dummy   | dummy     | Whether a movie is animated or not                                      |

### Type of Analyses

Besides **descriptive statistics**, in further assessment of whether there was a significant difference in rating between animation and non-animation movies, an **independent t-test** was performed. For this, the procedure of Hair et al. (2019) was adopted.

To test H1 and H2, a **linear regression** was conducted in R Studio. This method was chosen because it allows for examining the relationship between a continuous dependent variable (average IMDb rating) and multiple continuous or categorical independent variables, including interactions. For the independent variables, these were entered step-wise in three models, and then assessed on fitness based on the F-statistic and the Adjusted R². The following three hierarchical regression models were estimated;

1. *Model 1*: including the basic predictors. Whether a movie was an animation was dummy-coded into the variable `animation_dummy` (0 = non-animated, 1 = animated), while the release year was stored into `before_2010_dummy` (0 = since 2010, 1 = before 2010) and included. The interaction between variables was not yet tested in model 1.

2. *Model 2*: including the basic predictors and control variables. Other potential factors that were not specifically hypothesised but could influence ratings were added as control variables in model 2. This included `startYear`, `runtimeMinutes` and `numVotes`. In verifying whether the assumption of linearity was met, it was revealed to be violated for `runtimeMinutes` and `numVotes`, whereby these have been log transformed and entered into the model as `log_runtimeMinutes` and `log_numVotes`. 

3. *Model 3*: including the basic predictors and control variables and interactions. The expected moderation effects between `before_2010_dummy` and `animation_dummy`, and `animation_dummy` and `startYear` was included in order to test H1 and H2.

Besides the unstandardised effects, the standardised effects were also calculated since these allow to compare coefficients on their magnitude. Following the procedure of Field (2018) and Hair et al. (2019), each regression model was checked on the following assumptions;

- *Normality*: using the Shapiro-Wilk test, the Kolmogorov-Smirnov test and a histogram of residuals
- *Homoscedasticity* and *Linearity*: using a ZPRED vs ZRESID plot
- *Multicollinearity*: using the Variance Inflation Factor
- *Independence*: using the Durbin-Watson test

\newpage

## Chapter 4: Findings

### Descriptive Statistics

The runtime of films looks similar for the different subsets, ranging between 90 and 100 minutes. When it comes to average ratings, animated titles tend to score slightly higher on average, with a mean of 6.5 compared to 6.2 for other genres. For startyear the average ratings look similar. The animated movies are underrepresented in the subset. And it can be seen that since 2010 many more movies are available but the movies are rated less times per movie.

| Subset | Observations | Mean runtime minutes | Mean averageratings | Mean number of votes | SD averageratings |
|------------|------------|------------|------------|------------|------------|
| Animation | 1,846 | 90.5 | 6.51 | 43,393 | 1.08 |
| Non-Animation | 64,051 | 96.8 | 6.22 | 30,608 | 1.17 |
| Before 2010 | 20,537 | 97.0 | 6.29 | 35,085 | 1.14 |
| Since 2010 | 45,360 | 96.4 | 6.20 | 29,101 | 1.18 |

### Visualization of data

```{r, echo=FALSE, out.width="60%", fig.align="center"}
library(here)
# Line plot, average rating per year per type
knitr::include_graphics(here::here("gen/output/line_avg_rating_by_type.png"))
# Smooth plot, average rating per year per type
knitr::include_graphics(here::here("gen/output/smooth_avg_rating_by_type.png"))
# Boxplot, runtime
knitr::include_graphics(here::here("gen/output/boxplot_runtime.png"))
```

In the first plot the average rating over time for animated and non-animated movies can be seen. It can be seen that the ratings are close but animated movies are typically rated somewhat higher than non-animated movies.

In the second plot it can be seen that the average rating for animated movies is declining over time and the rating of non-animated movies is not stable but in the last years the rating is increasing.

In the last plot the distribution for runtime can be seen. It can be seen that for both genres the average runtime is similar and around 90/100 minutes. For both genres there are some outliers which are longer than 200 minutes, or under 50 minutes.


### T-Test

As visualised in \<graph 2\>, the average rating for animation movies with 6.51 (SD = 1.08) is higher then for non-animation movies with 6.22 (SD = 1.17). In further solidifying this, the independent t-test (see the full output in Appendix I) found that this difference, 0.29, BCa 95% CI [0.241, 0.341}, is significant t(1973) = 11.417, p =\< 0.001. Thus, on average, animation movies receive higher grades than non-animation movies.

### Regression Analysis

### Findings

The full regression output can be consulted in Appendix II. In the table below, a summary is provided of the significant relationships per model.

```{r results='asis', echo = FALSE}
library(knitr)

data <- data.frame(
  Variable = c(
    "before_2010_dummyRelease since 2010",
    "animation_dummyNon-Animation",
    "startYear",
    "log_runtimeMinutes",
    "log_numVotes",
    "before_2010_dummyRelease since 2010:animation_dummyNon-Animation",
    "animation_dummyNon-Animation:startYear"
  ),
  Model1_Estimate = c(-0.088223, -0.292777, NA, NA, NA, NA, NA),
  Model1_StdError = c(0.009831, 0.027595, NA, NA, NA, NA, NA),
  Model1_Standardised = c(-0.034909, -0.041273, NA, NA, NA, NA, NA),
  
  Model2_Estimate = c(-0.0699701, -0.2489657, NA, 0.1695445, 0.1769982, NA, NA),
  Model2_StdError = c(0.0173959, 0.0268355, NA, 0.0156716, 0.0028827, NA, NA),
  Model2_Standardised = c(-0.0276866, -0.0350970, NA, 0.0409379, 0.2326277, NA, NA),
  
  Model3_Estimate = c(NA, NA, NA, 0.1695846, 0.1769870, NA, NA),
  Model3_StdError = c(NA, NA, NA, 0.0156727, 0.0028830, NA, NA),
  Model3_Standardised = c(NA, NA, NA, 0.0409476, 0.2326131, NA, NA)
)

kable(data, caption = "Regression Results (Models 1–3)", digits = 6)

```



Model 1 includes only the main predictors (release period dummy (before vs. since 2010) and animation status) and therefore primarily tests H1, which concerns whether movies released since 2010 have lower ratings than those released before. Model 2 extends this specification by adding control variables for runtime, number of votes, and release year, allowing a more accurate estimate of the main effects while accounting for potential confounding influences. Model 3 introduces interaction terms between release period and animation and between animation and release year, to test H2.

In both Model 1 and Model 2, the start-year dummy has a significant effect on average movie ratings (p < 0.001). In the most basic model, movies released since 2010 on average score 0.088 lower than those released in the prior period (1995–2009). When control variables are added in model 2, this difference decreases slightly to 0.070. The first model reports a low adjusted R² (0.0029), indicating that the release period alone explains little of the variance in ratings. These findings statistically support H1, showing that the period of release (before versus since 2010) is significantly related to movie ratings, although the overall explanatory power of this variable is limited.

Model 3 adds the interaction terms to examine whether the relationship between release year and ratings differs between animated and non-animated films. Neither the interaction between release since 2010 × animation nor the interaction between start year × animation is statistically significant (p > 0.05). This suggests no strong evidence that the relationship between release year and ratings depends on animation status. The control variables (runtime and number of votes) remain significant and positive across models, indicating their consistent influence on ratings. Consequently, H2 is not statistically supported.

### Assumptions

Appendix III shows the full output of the assumptions checking of the regression models. Since model 3 is the highest in explanatory power, this finding section is specified to that model. Below, the summary can be found.

|        | Normality                                                                 | Linearity                              | Homoscedasticity                             | Multicollinearity                          | Independence                       |
|------------------|---------------------------------------------------------------------------|----------------------------------------|----------------------------------------------|-------------------------------------------|------------------------------------|
| **Tested**       | Shapiro-Wilk + Kolmogorov-Smirnov + Histogram show non-normality| ZPRED vs ZRESID shows linearity        | ZPRED vs ZRESID shows heteroscedasticity     | Variance Inflation Factor below 1          | Durbin-Watson test close to 2      |
| **Verdict**      | **VIOLATED**                                                              | **MET**                                | **VIOLATED**                                 | **MET**                                   | **MET**                             |



\newpage

## Chapter 5: Conclusions and Discussion

### Conclusion

Overall, the results indicate that movie ratings have declined slightly in the post-2010 era, supporting the notion that audiences have become more critical in the age of streaming. However, this temporal shift explains only a small portion of the variation in ratings, suggesting that other factors such as popularity and runtime play a more substantial role in how movies are evaluated. Moreover, the absence of a significant interaction effect implies that the changing rating patterns over time apply similarly to both animated and non-animated films. In sum, while there is evidence of a general negative trend in movie ratings after 2010 (H1), the moderation by animation status is not supported (H2).

### Discussion

The present study aimed to examine whether the release year of a movie influences its IMDb rating and whether this relationship differs between animated and non-animated movies. The findings show a slight but significant decline in average ratings for films released after 2010, providing partial support for H1. This outcome aligns with Moon, Bergey, and Iacobucci (2009), who argued that audiences have become more critical as their exposure to films increases. Likewise, Hadida et al. (2020) and Hennig-Thurau et al. (2021) described how the streaming era has intensified competition and expanded consumer choice, which may lead viewers to evaluate movies more harshly. Thus, the current results reinforce the notion that the expansion of digital content and on-demand viewing has reshaped expectations of film quality. 

However, while a temporal effect on ratings was confirmed, the moderation effect of animation (H2) was not supported. Contrary to Larson (2025), who proposed that animated films are perceived as more timeless due to their visual consistency and limited dependence on aging actors, the present analysis found no significant difference in how ratings changed over time for animation compared to live action. One possible explanation is that animated films have also evolved considerably in style and storytelling sophistication. As animation increasingly targets adult audiences, nostalgia may be offset by higher critical standards and greater scrutiny of production quality. Furthermore, because animated movies make up a smaller portion of total releases, any distinct pattern may be diluted by the predominance of live-action titles in the data set.

Although statistically significant, the models explain only a small proportion of variance in IMDb ratings (adjusted R2 ≈ 0.06). This indicates that the timing of release alone cannot account for the complexity of audience evaluations. Other influences, such as genre preferences, marketing exposure, critical reviews, or star power, likely play a much larger role. Nevertheless, the study provides empirical support for the idea that streaming-era audiences have become incrementally more discerning and that this shift applies broadly across both animated and non-animated movies.


### Limitations

Several limitations should be considered when interpreting these findings. Firstly, the analysis relied solely on IMDb data, which represents a self-selected community of users rather than a random sample of movie consumers. Ratings on the platform may therefore reflect demographic or cultural biases, such as the overrepresentation of younger or more media-savvy audiences.

Furthermore, the dataset captured IMDb scores at a single point in time. However, because ratings can evolve after release, possibly increasing with nostalgia or decreasing due to review-bombing, the cross-sectional nature of the data prevents analysis of longitudinal rating changes.

Another limitation is that the temporal variable was simplified into a binary indicator (before vs. since 2010). While this aligns with the introduction of major streaming services, it limits the ability to detect gradual or nonlinear trends across individual years.

Moreover, genre overlap may confound the results. Many animated movies also belong to other genres such as adventure or comedy, which independently influence ratings.

Additionally, several regression assumptions, specifically normality and homoscedasticity, were violated, as shown in Appendix III. These violations are likely a result of the large sample size and the nature of IMDb ratings, which are bounded between 0 and 10 and tend to cluster towards higher scores. As Field (2018) notes, even small deviations from normality can appear statistically significant when working with large data sets. Although such violations are common in social-science data and may not critically distort the estimates, they can reduce the precision of statistical inference and should be interpreted with caution. However, it is also important to note that these assumptions are not considered the most important of all the necessary assumptions and thus should not pose too much of a concern.

Lastly, the relatively low adjusted R2 suggests omitted-variable bias. Factors such as production budget, marketing effort, or critical acclaim were not included but could have a substantial effect on audience ratings. Future studies could incorporate these variables and employ longitudinal or mixed-effects models to better capture temporal and genre-specific dynamics.


### Future Research

With data being created on a daily basis, the analysis of IMDB data sets remains an ongoing process. By repeating this type of research over time it could reveal potential trends in IMDb ratings for animation movies compared to non-animated movies.

Future research could focus more on the role of movie popularity and its influence on IMDB rating. Many animated films are reboots of older, nostalgic classics, which may affect audiences perception and engagement. These type of movies might attract more reviews due to their established fan base and may receive more critical evaluations because viewers have a direct point of c comparison with the original.

In addition, it would be valuable to examine whether there is a significant different in ratings between animated reboots and newly created animated concepts. These researches can also be done on TV shows, bring a different angle with some shows from gen-z youth still continuing to be produced in current day of time.

\newpage

## Reference List

Bollen, D., Graus, M. P., & Willemsen, M. C. (2012). Remembering the stars?: effect of time on preference retrieval from memory. Proceedings of the sixth ACM conference on Recommender systems.<https://doi.org/10.1145/2365952.2365998>

Hadida, A. L., Lampel, J., Walls, W. D., & Joshi, A. (2020). Hollywood Studio Filmmaking in the Age of Netflix: a Tale of Two Institutional Logics. Journal of Cultural Economics, 45(2), 213–238. <https://doi.org/10.1007/s10824-020-09379-z>

Hennig-Thurau, T., Ravid, S. A., & Sorenson, O. (2021). The Economics of Filmed Entertainment in the Digital Era. Journal of Cultural Economics, 45(2), 157–170. <https://doi.org/10.1007/s10824-021-09407-6>

Kumar, L. (2023, April). A Study On The Impact Of The OTT Platform On The Cinema With The Special Reference On The Cinema Audience. ResearchGate; unknown. <https://www.researchgate.net/publication/376650380_A_Study_On_The_Impact_Of_The_OTT_Platform_On_The_Cinema_With_The_Special_Reference_On_The_Cinema_Audience>

Larson, V. J. (2025). Philosophy in filmmaking: Animation vs. live action (Honors Program Theses No. 976) [Undergraduate thesis, University of Northern Iowa]. University of Northern Iowa Repository. <https://scholarworks.uni.edu/cgi/viewcontent.cgi?article=2004&context=hpt>

Lizardi, R. (2020). The future of nostalgia is inevitable: Reflections on mediated nostalgia. In M. H. Jacobsen (Ed.), Nostalgia Now: Cross-disciplinary perspectives on the past in the present (1st ed., pp. 147-161). Routledge. <https://doi.org/10.4324/9780429287602-8>

Moon, S., Bergey, P. K., & Iacobucci, D. (2009). Dynamic Effects among Movie Ratings, Movie Revenues, and Viewer Satisfaction. Journal Of Marketing, 74(1), 108–121. <https://doi.org/10.1509/jmkg.74.1.108>

Oberoi, S. (2024, December 3). The Evolution of Netflix: from DVD Rentals to Global Streaming Leader. Seat11a.com. <https://seat11a.com/blog-the-evolution-of-netflix-from-dvd-rentals-to-global-streaming-leader/>

Ramos, M., Calvão, A. M., & Anteneodo, C. (2015). Statistical patterns in movie rating behavior. PLOS ONE, 10(8), e0136083. <https://doi.org/10.1371/journal.pone.0136083>

Sun, Z. (2023). What does cgi digital technology bring to the sustainable development of animated films?. Sustainability, 15(14), 10895. <https://doi.org/10.3390/su151410895>

Thompson, B. (2024, May 25). The Rise and Fall of Streaming TV? –Michigan Journal of Economics. Michigan Journal of Economics. <https://sites.lsa.umich.edu/mje/2024/05/25/the-rise-and-fall-of-streaming-tv/>

\newpage

## Appendix I - Results T-Test

```{r independent t-test, echo=FALSE}
print(readLines("../gen/output/ttest_rating.txt"))
```

\newpage

## Appendix II - Results Multiple Regression

### Model 1

```{r model 1, echo=FALSE}
model1 <- print(readLines("../gen/output/lr_model_basic.txt"))
```

\newpage

### Model 2

```{r model 2, echo=FALSE}
model2 <- print(readLines("../gen/output/lr_model_with_control_variables.txt"))
```

\newpage

### Model 3

```{r model 3, echo=FALSE}
model3 <- print(readLines("../gen/output/lr_model_with_interaction.txt"))
```

\newpage

## Appendix III -Assumptions Results Multiple Regression

### Assumptions model 1

```{r assumptions model 1, echo=FALSE}
assumptionsmodel1 <- print(readLines("../gen/output/assumption_checks_model1.txt"))
```

```{r fig.align='center', echo=FALSE, out.width='50%'}
knitr::include_graphics("../gen/output/assumptions_histogram_MODEL1_unstandardised.png")
```

```{r fig.align='center', echo=FALSE, out.width='50%'}
knitr::include_graphics("../gen/output/assumptions_plot_ZPREDvsZRESID_MODEL1_unstandardised.png")
```

\newpage

### Assumptions model 2

```{r assumptions model 2, echo=FALSE}
assumptionsmodel2 <- print(readLines("../gen/output/assumption_checks_model2.txt"))
```

```{r fig.align='center', echo=FALSE, out.width='50%'}
knitr::include_graphics("../gen/output/assumptions_histogram_MODEL2_unstandardised.png")
```

```{r fig.align='center', echo=FALSE, out.width='50%'}
knitr::include_graphics("../gen/output/assumptions_plot_ZPREDvsZRESID_MODEL2_unstandardised.png")
```

\newpage

### Assumptions model 3

```{r assumptions model 3, echo=FALSE}
assumptionsmodel3 <- print(readLines("../gen/output/assumption_checks_model3.txt"))
```

```{r fig.align='center', echo=FALSE, out.width='50%'}
knitr::include_graphics("../gen/output/assumptions_histogram_MODEL3_unstandardised.png")
```

```{r fig.align='center', echo=FALSE, out.width='50%'}
knitr::include_graphics("../gen/output/assumptions_plot_ZPREDvsZRESID_MODEL3_unstandardised.png")
```
